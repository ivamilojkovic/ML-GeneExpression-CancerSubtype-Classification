{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ivamilojkovic/Breast-Cancer-Analysis/src\n"
     ]
    }
   ],
   "source": [
    "%cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle, os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utils import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "sns.set_theme()\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 4)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multilabel_metrics import semi_relaxed_accuracy, ordered_subset_accuracy, k_orders_subset_accuracy, relaxed_accuracy, partial_accuracy, secondary_accuracy\n",
    "from sklearn.metrics import label_ranking_average_precision_score, average_precision_score\n",
    "def print_all_scores(y_test, predictions, prob_predictions, label_orig, label_pam50, y_corr, txt_file_name=None, k=[1]):\n",
    "\n",
    "    # Compute scores on test set\n",
    "    subset_acc = accuracy_score(y_test, predictions)\n",
    "    relax_pam50_acc = relaxed_accuracy(label_pam50, predictions)\n",
    "    relax_orig_acc = relaxed_accuracy(label_orig, predictions)\n",
    "    partial_acc = partial_accuracy(y_test, predictions)\n",
    "    hamm_loss = hamming_loss(y_test, predictions)\n",
    "    rank_avg_prec = label_ranking_average_precision_score(y_test, prob_predictions)\n",
    "    avg_prec = average_precision_score(y_test, prob_predictions)\n",
    "\n",
    "    print('\\nTest accuracy: {}'.format(subset_acc))\n",
    "    print('Test relaxed accuracy (PAM50): {}'.format(relax_pam50_acc))\n",
    "    print('Test relaxed accuracy (original): {}'.format(relax_orig_acc))\n",
    "    print('Partial accuracy: {}'.format(partial_acc))\n",
    "    print('Test Hamming loss: {}\\n'.format(hamm_loss))\n",
    "    print('Ranking average precision: ', rank_avg_prec)\n",
    "    print('Average precision: ', avg_prec)\n",
    "\n",
    "    prec_weighted = precision_score(y_test, predictions, \n",
    "                                    average='weighted', zero_division=1)\n",
    "    rec_weighted = recall_score(y_test, predictions, \n",
    "                            average='weighted', zero_division=1)\n",
    "    f1_weighted = f1_score(y_test, predictions, \n",
    "                        average='weighted', zero_division=1)\n",
    "\n",
    "    print('Test precision (weighted): {}'.format(prec_weighted))\n",
    "    print('Test recall (weighted): {}'.format(rec_weighted))\n",
    "    print('Test f1 score (weighted): {}\\n'.format(f1_weighted))\n",
    "\n",
    "    prec_macro = precision_score(y_test, predictions, \n",
    "                                average='macro', zero_division=1)\n",
    "    rec_macro = recall_score(y_test, predictions, \n",
    "                            average='macro', zero_division=1)\n",
    "    f1_macro = f1_score(y_test, predictions, \n",
    "                        average='macro', zero_division=1)\n",
    "\n",
    "    print('Test precision (macro): {}'.format(prec_macro))\n",
    "    print('Test recall (macro): {}'.format(rec_macro))\n",
    "    print('Test f1 score (macro): {}\\n'.format(f1_macro))\n",
    "\n",
    "    prec_micro = precision_score(y_test, predictions, \n",
    "                                average='micro', zero_division=1)\n",
    "    rec_micro = recall_score(y_test, predictions, \n",
    "                            average='micro', zero_division=1)\n",
    "    f1_micro = f1_score(y_test, predictions, \n",
    "                        average='micro', zero_division=1)\n",
    "    \n",
    "    print('Test precision (micro): {}'.format(prec_micro))\n",
    "    print('Test recall (micro): {}'.format(rec_micro))\n",
    "    print('Test f1 score (micro): {}\\n'.format(f1_micro))\n",
    "\n",
    "    # Additional metrics\n",
    "    # semi = semi_relaxed_accuracy(y_prob_pred=prob_predictions, y_true=y_test)\n",
    "    ordered = ordered_subset_accuracy(y_test_corr=y_corr, y_test_mcut=y_test, \n",
    "                                      predictions=predictions, prob_predictions=prob_predictions)\n",
    "\n",
    "    # print('Semi-relexed: {}'.format(semi))\n",
    "    print('Ordered subset acc: {}'.format(ordered))\n",
    "    for order in k:\n",
    "        k_ordered = k_orders_subset_accuracy(y_test_mcut=y_test, predictions=predictions, \n",
    "                                            y_test_corr=y_corr, prob_predictions=prob_predictions, k=order)\n",
    "        print('Order {} accuracy: {}'.format(order, k_ordered))\n",
    "\n",
    "    sec_acc = secondary_accuracy(y_test_mcut=y_test, predictions=predictions, \n",
    "                                            y_test_corr=y_corr, prob_predictions=prob_predictions, k=2)\n",
    "    print('\\nSecondary accuracy: ', sec_acc)\n",
    "    \n",
    "    if txt_file_name != None:\n",
    "        with open(txt_file_name, 'w') as file:\n",
    "\n",
    "            file.write('--- Test scores ---\\n')\n",
    "            file.write(f'Subset accuracy: {subset_acc}\\n')\n",
    "            file.write(f'Relaxed (PAM50) accuracy: {relax_pam50_acc}\\n')\n",
    "            file.write(f'Relaxed (original) accuracy: {relax_orig_acc}\\n')\n",
    "            file.write(f'Partial accuracy: {partial_acc}\\n')\n",
    "            file.write(f'Hamming loss: {hamm_loss}\\n')\n",
    "            file.write(f'Ranking average precision: {rank_avg_prec}\\n')\n",
    "            file.write(f'Average precision: {avg_prec}\\n\\n')\n",
    "\n",
    "            file.write(' - Weighted scores -\\n')\n",
    "            file.write(f'Precision: {prec_weighted}\\n')\n",
    "            file.write(f'Recall: {rec_weighted}\\n')\n",
    "            file.write(f'F1 score: {f1_weighted}\\n\\n')\n",
    "\n",
    "            file.write(' - Macro scores -\\n')\n",
    "            file.write(f'Precision: {prec_macro}\\n')\n",
    "            file.write(f'Recall: {rec_macro}\\n')\n",
    "            file.write(f'F1 score: {f1_macro}\\n\\n')\n",
    "\n",
    "            file.write(' - Micro scores -\\n')\n",
    "            file.write(f'Precision: {prec_micro}\\n')\n",
    "            file.write(f'Recall: {rec_micro}\\n')\n",
    "            file.write(f'F1 score: {f1_micro}\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 columns with more than 80% of Null values!\n",
      "There are 22722 columns with more than 20% of count values greater than 4!\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing import remove_extreme\n",
    "\n",
    "# Load test data (the split is the same as in the training workflow)\n",
    "with open('../data/dataset_multilabel.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "    label_values = ['Basal', 'Her2', 'LumA', 'LumB', 'Normal']\n",
    "    X = data.drop(columns=['expert_PAM50_subtype', 'tcga_id',\n",
    "                           'Subtype-from Parker centroids',\t'MaxCorr',\n",
    "                            'Basal', 'Her2', 'LumA', 'LumB', 'Normal'], inplace=False)\n",
    "    y_orig = data.expert_PAM50_subtype\n",
    "    y_pam50 = data['Subtype-from Parker centroids']\n",
    "    \n",
    "DATA_TYPE = 'BRCA'\n",
    "\n",
    "########################### Load the data ###########################\n",
    "if DATA_TYPE == 'CRIS':\n",
    "    label_values = ['CRIS.A', 'CRIS.B', 'CRIS.C', 'CRIS.D', 'CRIS.E']\n",
    "    with open('../data/tcga_cris_raw_24356_620samples.pkl', 'rb') as file:\n",
    "        data = pickle.load(file) \n",
    "    X = data.drop(columns=['Patient ID', 'Subtype-from Parker centroids'] + label_values, inplace=False)\n",
    "    y_pam50 = data['Subtype-from Parker centroids']\n",
    "    y_orig = data['Subtype-from Parker centroids'] # this is not important\n",
    "\n",
    "# Remove extreme values (genes, samples) from initial preprocessing\n",
    "X, potential_samples_to_remove, \\\n",
    "    feat_to_remove, feat_to_keep = remove_extreme(X, change_X = True)\n",
    "\n",
    "# Take labels on whole dataset for PAM50\n",
    "y_corr = data[label_values]\n",
    "y_corr_non_neg = discard_negative_correlations(y_corr)\n",
    "\n",
    "# M-cut strategy to assign labels on whole dataset\n",
    "y_mcut_labels, _ = m_cut_strategy_class_assignment(y_corr, non_neg_values=True)\n",
    "y_mcut_labels_neg, _ = m_cut_strategy_class_assignment(y_corr, non_neg_values=False)\n",
    "\n",
    "# Compute labels from two strategies (M-cut and 5th percentile)\n",
    "y_mcut_5perc_labels, _ = create_mcut_nth_percentile_labels(\n",
    "    m_cut_labels=y_mcut_labels,\n",
    "    correlations=y_corr_non_neg,\n",
    "    y=y_pam50,\n",
    "    keep_primary=False,\n",
    "    N=5\n",
    ")\n",
    "\n",
    "X_train, X_test, \\\n",
    "y_train_pam50, y_test_pam50, \\\n",
    "y_train_mcut, y_test_mcut, \\\n",
    "y_train_orig, y_test_orig, \\\n",
    "y_train_5perc, y_test_5perc, \\\n",
    "y_train_corr, y_test_corr = \\\n",
    "    train_test_split(X, y_pam50, y_mcut_labels, y_orig, \n",
    "                    y_mcut_5perc_labels, y_corr_non_neg, test_size=0.3, random_state=1, stratify=y_pam50)\n",
    "\n",
    "# Data standardization | normalization\n",
    "X_train = X_train.divide(X_train.sum(axis=1), axis=0) * 1e6\n",
    "X_test = X_test.divide(X_test.sum(axis=1), axis=0) * 1e6\n",
    "scaler = FunctionTransformer(log_transform)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "\n",
    "# Load selected features\n",
    "if DATA_TYPE=='CRIS':\n",
    "    with open('../data/cris/new2_without_corr_removed_feat_select_gt_40_perc_occur.pkl', 'rb') as file:\n",
    "        selected_feat = pickle.load(file)\n",
    "else:\n",
    "    with open('../data/brca/without_corr_removed_feat_select_gt_50_perc_occur.pkl', 'rb') as file:\n",
    "        selected_feat = pickle.load(file)\n",
    "\n",
    "X_train_scaled_selected = X_train_scaled[list(selected_feat)]\n",
    "X_test_scaled_selected = X_test_scaled[list(selected_feat)]\n",
    "\n",
    "# One-hot encoding of original and PAM50 labels\n",
    "y_train_orig = pd.get_dummies(y_train_orig)\n",
    "y_test_orig = pd.get_dummies(y_test_orig)\n",
    "y_train_pam50 = pd.get_dummies(y_train_pam50)\n",
    "y_test_pam50 = pd.get_dummies(y_test_pam50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186, 53)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/Users/ivamilojkovic/Breast-Cancer-Analysis/test_samples.pkl', 'rb') as f:\n",
    "    test_main_idx = pickle.load(f)\n",
    "len(test_main_idx), len(set(y_test_5perc.index).intersection(set(test_main_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define a mapping dictionary\n",
    "mapping = {0: 'Basal',1: 'Her2', 2: 'LumA', 3: 'LumB', 4: 'Normal'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_brca_sl = '../final_results/BRCA/single-label/SUBTYPE_PAM50/feat_select_hybrid'\n",
    "\n",
    "# Loading the best models for each approach in single-label\n",
    "with open(os.path.join(path_brca_sl, 'bestmodel_XGBoost_run_28-08-2023_05:09:55.pkl'), 'rb') as f:\n",
    "    brca_model_xgb = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(path_brca_sl, 'bestmodel_LogisticRegression_run_28-08-2023_13:08:54.pkl'), 'rb') as f:\n",
    "    brca_model_lr = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(path_brca_sl, 'bestmodel_RandomForest_run_28-08-2023_13:44:47.pkl'), 'rb') as f:\n",
    "    brca_model_rf = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(path_brca_sl, 'bestmodel_SVC_run_28-08-2023_14:00:35.pkl'), 'rb') as f:\n",
    "    brca_model_svm = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(path_brca_sl, 'bestmodel_AdaBoost_run_28-08-2023_16:33:41.pkl'), 'rb') as f:\n",
    "    brca_model_adaboost = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(path_brca_sl, 'bestmodel_DecisionTree_run_28-08-2023_13:34:10.pkl'), 'rb') as f:\n",
    "    brca_model_dectree = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(path_brca_sl, 'bestmodel_KNN_run_28-08-2023_13:33:43.pkl'), 'rb') as f:\n",
    "    brca_model_knn = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(path_brca_sl, 'bestmodel_LightGBM_run_28-08-2023_14:43:23.pkl'), 'rb') as f:\n",
    "    brca_model_lgbm = pickle.load(f)\n",
    "\n",
    "# Compute predictions\n",
    "xgb_preds = brca_model_xgb.predict(X_test_scaled_selected)\n",
    "xgb_preds = pd.Series(xgb_preds, index=y_test_5perc.index).map(mapping)\n",
    "\n",
    "lr_preds = brca_model_lr.predict(X_test_scaled_selected)\n",
    "lr_preds = pd.Series(lr_preds, index=y_test_5perc.index).map(mapping)\n",
    "\n",
    "svm_preds = brca_model_svm.predict(X_test_scaled_selected)\n",
    "svm_preds = pd.Series(svm_preds, index=y_test_5perc.index).map(mapping)\n",
    "\n",
    "rf_preds = brca_model_rf.predict(X_test_scaled_selected)\n",
    "rf_preds = pd.Series(rf_preds, index=y_test_5perc.index).map(mapping)\n",
    "# ----------\n",
    "ada_preds = brca_model_adaboost.predict(X_test_scaled_selected)\n",
    "ada_preds = pd.Series(ada_preds, index=y_test_5perc.index).map(mapping)\n",
    "\n",
    "knn_preds = brca_model_knn.predict(X_test_scaled_selected)\n",
    "knn_preds = pd.Series(knn_preds, index=y_test_5perc.index).map(mapping)\n",
    "\n",
    "dectree_preds = brca_model_dectree.predict(X_test_scaled_selected)\n",
    "dectree_preds = pd.Series(dectree_preds, index=y_test_5perc.index).map(mapping)\n",
    "\n",
    "lgbm_preds = brca_model_lgbm.predict(X_test_scaled_selected)\n",
    "lgbm_preds = pd.Series(lgbm_preds, index=y_test_5perc.index).map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_brca_ml = '../final_results/BRCA/multi-label'\n",
    "path_brca_ml_pt = os.path.join(path_brca_ml, '03-09-2023_18:41:10')\n",
    "\n",
    "# Logistic Regression - Binary Relevance\n",
    "with open(os.path.join(path_brca_ml_pt, 'BR_LRegression_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_lr_br = pickle.load(file)\n",
    "# Logistic Regression - Classifier Chain \n",
    "with open(os.path.join(path_brca_ml_pt, 'CC_LRegression_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_lr_cc = pickle.load(file)\n",
    "# Logistic Regression - Label Powerset\n",
    "with open(os.path.join(path_brca_ml_pt, 'LP_LRegression_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_lr_lp = pickle.load(file)\n",
    "\n",
    "# XGBoost - Binary Relevance\n",
    "with open(os.path.join(path_brca_ml_pt, 'BR_XGBoost_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_xgb_br = pickle.load(file)\n",
    "# XGBoost - Classifier Chain \n",
    "with open(os.path.join(path_brca_ml_pt, 'CC_XGBoost_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_xgb_cc = pickle.load(file)\n",
    "# XGBoost - Label Powerset\n",
    "with open(os.path.join(path_brca_ml_pt, 'LP_XGBoost_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_xgb_lp = pickle.load(file)\n",
    "\n",
    "# Random Forest - Binary Relevance\n",
    "with open(os.path.join(path_brca_ml_pt, 'BR_RForest_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_rf_br = pickle.load(file)\n",
    "# Random Forest - Classifier Chain\n",
    "with open(os.path.join(path_brca_ml_pt, 'CC_RForest_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_rf_cc = pickle.load(file)\n",
    "# Random Forest - Label Powesret\n",
    "with open(os.path.join(path_brca_ml_pt, 'LP_RForest_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_rf_lp = pickle.load(file)\n",
    "\n",
    "# SVC - Binary Relevance \n",
    "with open(os.path.join(path_brca_ml_pt, 'BR_SVC_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_svm_br = pickle.load(file)\n",
    "# SVC - Classifier Chain\n",
    "with open(os.path.join(path_brca_ml_pt, 'CC_SVC_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_svm_cc = pickle.load(file)\n",
    "# SVC - Label Powesret\n",
    "with open(os.path.join(path_brca_ml_pt, 'LP_SVC_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_svm_lp = pickle.load(file)\n",
    "\n",
    "\n",
    "############################ Algorithm Adaptation and Ensemble #############################\n",
    "path_brca_ml_aa = os.path.join(path_brca_ml, '30-08-2023_03:55:43')\n",
    "\n",
    "with open(os.path.join(path_brca_ml_aa, 'MLkNN_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_mlknn = pickle.load(file)\n",
    "with open(os.path.join(path_brca_ml_aa, 'MLARAM_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_mlaram = pickle.load(file)\n",
    "\n",
    "with open(os.path.join(path_brca_ml_aa, 'EnsembleCC_XGBoost_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_ecc_xgb = pickle.load(file)\n",
    "with open(os.path.join(path_brca_ml_aa, 'EnsembleCC_RForest_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_ecc_rf = pickle.load(file)\n",
    "with open(os.path.join(path_brca_ml_aa, 'EnsembleCC_LRegression_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_ecc_lr = pickle.load(file)\n",
    "with open(os.path.join(path_brca_ml_aa, 'EnsembleCC_SVC_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_ecc_svm = pickle.load(file)\n",
    "\n",
    "with open(os.path.join(path_brca_ml_aa, 'EnsembleRakel_XGBoost_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_er_xgb = pickle.load(file)\n",
    "with open(os.path.join(path_brca_ml_aa, 'EnsembleRakel_RForest_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_er_rf = pickle.load(file)\n",
    "with open(os.path.join(path_brca_ml_aa, 'EnsembleRakel_LRegression_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_er_lr = pickle.load(file)\n",
    "with open(os.path.join(path_brca_ml_aa, 'EnsembleRakel_SVC_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_er_svm = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': None, 'steps': [('classifier', RakelD(base_classifier=XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                                     callbacks=None, colsample_bylevel=None,\n",
      "                                     colsample_bynode=None,\n",
      "                                     colsample_bytree=0.5,\n",
      "                                     early_stopping_rounds=None,\n",
      "                                     enable_categorical=False, eval_metric=None,\n",
      "                                     feature_types=None, gamma=0.25,\n",
      "                                     gpu_id=None, grow_policy=None,\n",
      "                                     importance_type=None,\n",
      "                                     interaction_constraints=None,\n",
      "                                     learning_rate=0.05, max_bin=None,\n",
      "                                     max_cat_threshold=None,\n",
      "                                     max_cat_to_onehot=None,\n",
      "                                     max_delta_step=None, max_depth=5,\n",
      "                                     max_leaves=None, min_child_weight=None,\n",
      "                                     missing=nan, monotone_constraints=None,\n",
      "                                     n_estimators=100, n_jobs=None,\n",
      "                                     num_parallel_tree=None,\n",
      "                                     objective='multi:softprob', predictor=None, ...)))], 'verbose': False, 'classifier': RakelD(base_classifier=XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                                     callbacks=None, colsample_bylevel=None,\n",
      "                                     colsample_bynode=None,\n",
      "                                     colsample_bytree=0.5,\n",
      "                                     early_stopping_rounds=None,\n",
      "                                     enable_categorical=False, eval_metric=None,\n",
      "                                     feature_types=None, gamma=0.25,\n",
      "                                     gpu_id=None, grow_policy=None,\n",
      "                                     importance_type=None,\n",
      "                                     interaction_constraints=None,\n",
      "                                     learning_rate=0.05, max_bin=None,\n",
      "                                     max_cat_threshold=None,\n",
      "                                     max_cat_to_onehot=None,\n",
      "                                     max_delta_step=None, max_depth=5,\n",
      "                                     max_leaves=None, min_child_weight=None,\n",
      "                                     missing=nan, monotone_constraints=None,\n",
      "                                     n_estimators=100, n_jobs=None,\n",
      "                                     num_parallel_tree=None,\n",
      "                                     objective='multi:softprob', predictor=None, ...)), 'classifier__base_classifier': XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.5, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=0.25, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              objective='multi:softprob', predictor=None, ...), 'classifier__base_classifier__objective': 'multi:softprob', 'classifier__base_classifier__use_label_encoder': None, 'classifier__base_classifier__base_score': 0.5, 'classifier__base_classifier__booster': 'gbtree', 'classifier__base_classifier__callbacks': None, 'classifier__base_classifier__colsample_bylevel': None, 'classifier__base_classifier__colsample_bynode': None, 'classifier__base_classifier__colsample_bytree': 0.5, 'classifier__base_classifier__early_stopping_rounds': None, 'classifier__base_classifier__enable_categorical': False, 'classifier__base_classifier__eval_metric': None, 'classifier__base_classifier__feature_types': None, 'classifier__base_classifier__gamma': 0.25, 'classifier__base_classifier__gpu_id': None, 'classifier__base_classifier__grow_policy': None, 'classifier__base_classifier__importance_type': None, 'classifier__base_classifier__interaction_constraints': None, 'classifier__base_classifier__learning_rate': 0.05, 'classifier__base_classifier__max_bin': None, 'classifier__base_classifier__max_cat_threshold': None, 'classifier__base_classifier__max_cat_to_onehot': None, 'classifier__base_classifier__max_delta_step': None, 'classifier__base_classifier__max_depth': 5, 'classifier__base_classifier__max_leaves': None, 'classifier__base_classifier__min_child_weight': None, 'classifier__base_classifier__missing': nan, 'classifier__base_classifier__monotone_constraints': None, 'classifier__base_classifier__n_estimators': 100, 'classifier__base_classifier__n_jobs': None, 'classifier__base_classifier__num_parallel_tree': None, 'classifier__base_classifier__predictor': None, 'classifier__base_classifier__random_state': 4, 'classifier__base_classifier__reg_alpha': 0, 'classifier__base_classifier__reg_lambda': 1, 'classifier__base_classifier__sampling_method': None, 'classifier__base_classifier__scale_pos_weight': None, 'classifier__base_classifier__subsample': 0.8, 'classifier__base_classifier__tree_method': None, 'classifier__base_classifier__validate_parameters': None, 'classifier__base_classifier__verbosity': None, 'classifier__base_classifier_require_dense': None, 'classifier__labelset_size': 3}\n"
     ]
    }
   ],
   "source": [
    "print(brca_ml_model_er_xgb.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Define a mapping dictionary\n",
    "mapping = {0: 'Basal', 1: 'Her2', 2: 'LumA', 3: 'LumB', 4: 'Normal'}\n",
    "\n",
    "## Get the predictions and probabilities for each model and set the original test indices\n",
    "# X_test_scaled_selected = X_scaled_selected\n",
    "# y_test_5perc = y_mcut_5perc_labels\n",
    "\n",
    "############################### XGBoost ###############################\n",
    "xgb_br_preds = brca_ml_model_xgb_br.predict(X_test_scaled_selected).toarray()\n",
    "xgb_br_preds = pd.DataFrame(xgb_br_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "xgb_br_prob_preds = brca_ml_model_xgb_br.predict_proba(X_test_scaled_selected).toarray()\n",
    "xgb_br_prob_preds = pd.DataFrame(xgb_br_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "xgb_cc_preds = brca_ml_model_xgb_cc.predict(X_test_scaled_selected).toarray()\n",
    "xgb_cc_preds = pd.DataFrame(xgb_cc_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "xgb_cc_prob_preds = brca_ml_model_xgb_cc.predict_proba(X_test_scaled_selected).toarray()\n",
    "xgb_cc_prob_preds = pd.DataFrame(xgb_cc_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "# ############################### Logistic Regression ###############################\n",
    "lr_br_preds = brca_ml_model_lr_br.predict(X_test_scaled_selected).toarray()\n",
    "lr_br_preds = pd.DataFrame(lr_br_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "lr_br_prob_preds = brca_ml_model_lr_br.predict_proba(X_test_scaled_selected).toarray()\n",
    "lr_br_prob_preds = pd.DataFrame(lr_br_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "lr_cc_preds = brca_ml_model_lr_cc.predict(X_test_scaled_selected).toarray()\n",
    "lr_cc_preds = pd.DataFrame(lr_cc_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "lr_cc_prob_preds = brca_ml_model_lr_cc.predict_proba(X_test_scaled_selected).toarray()\n",
    "lr_cc_prob_preds = pd.DataFrame(lr_cc_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "# ############################### SVM ###############################\n",
    "svm_lp_preds = brca_ml_model_svm_lp.predict(X_test_scaled_selected).toarray()\n",
    "svm_lp_preds = pd.DataFrame(svm_lp_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "svm_lp_prob_preds = brca_ml_model_svm_lp.predict_proba(X_test_scaled_selected).toarray()\n",
    "svm_lp_prob_preds = pd.DataFrame(svm_lp_prob_preds, index=y_test_5perc.index, columns=y_test_5perc.columns)\n",
    "\n",
    "# ############################### Random Forest ###############################\n",
    "rf_lp_preds = brca_ml_model_rf_lp.predict(X_test_scaled_selected).toarray()\n",
    "rf_lp_preds = pd.DataFrame(rf_lp_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "rf_lp_prob_preds = brca_ml_model_rf_lp.predict_proba(X_test_scaled_selected).toarray()\n",
    "rf_lp_prob_preds = pd.DataFrame(rf_lp_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "# NOT OPTIMAL\n",
    "xgb_lp_preds = brca_ml_model_xgb_lp.predict(X_test_scaled_selected).toarray()\n",
    "xgb_lp_preds = pd.DataFrame(xgb_lp_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "xgb_lp_prob_preds = brca_ml_model_xgb_lp.predict_proba(X_test_scaled_selected).toarray()\n",
    "xgb_lp_prob_preds = pd.DataFrame(xgb_lp_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "lr_lp_preds = brca_ml_model_lr_lp.predict(X_test_scaled_selected).toarray()\n",
    "lr_lp_preds = pd.DataFrame(lr_lp_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "lr_lp_prob_preds = brca_ml_model_lr_lp.predict_proba(X_test_scaled_selected).toarray()\n",
    "lr_lp_prob_preds = pd.DataFrame(lr_lp_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "svm_br_preds = brca_ml_model_svm_br.predict(X_test_scaled_selected).toarray()\n",
    "svm_br_preds = pd.DataFrame(svm_br_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "svm_br_prob_preds = brca_ml_model_svm_br.predict_proba(X_test_scaled_selected).toarray()\n",
    "svm_br_prob_preds = pd.DataFrame(svm_br_prob_preds, index=y_test_5perc.index, columns=y_test_5perc.columns)\n",
    "\n",
    "svm_cc_preds = brca_ml_model_svm_cc.predict(X_test_scaled_selected).toarray()\n",
    "svm_cc_preds = pd.DataFrame(svm_cc_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "svm_cc_prob_preds = brca_ml_model_svm_cc.predict_proba(X_test_scaled_selected).toarray()\n",
    "svm_cc_prob_preds = pd.DataFrame(svm_cc_prob_preds, index=y_test_5perc.index, columns=y_test_5perc.columns)\n",
    "\n",
    "rf_br_preds = brca_ml_model_rf_br.predict(X_test_scaled_selected).toarray()\n",
    "rf_br_preds = pd.DataFrame(rf_br_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "rf_br_prob_preds = brca_ml_model_rf_br.predict_proba(X_test_scaled_selected).toarray()\n",
    "rf_br_prob_preds = pd.DataFrame(rf_br_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "rf_cc_preds = brca_ml_model_rf_cc.predict(X_test_scaled_selected).toarray()\n",
    "rf_cc_preds = pd.DataFrame(rf_cc_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "rf_cc_prob_preds = brca_ml_model_rf_cc.predict_proba(X_test_scaled_selected).toarray()\n",
    "rf_cc_prob_preds = pd.DataFrame(rf_cc_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "############################ Algorithm Adaptation #############################\n",
    "mlknn_preds = brca_ml_model_mlknn.predict(X_test_scaled_selected).toarray()\n",
    "mlknn_preds = pd.DataFrame(mlknn_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "mlknn_prob_preds = brca_ml_model_mlknn.predict_proba(X_test_scaled_selected).toarray()\n",
    "mlknn_prob_preds = pd.DataFrame(mlknn_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "mlaram_preds = brca_ml_model_mlaram.predict(X_test_scaled_selected.values)\n",
    "mlaram_preds = pd.DataFrame(mlaram_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "mlaram_prob_preds = brca_ml_model_mlaram.predict_proba(X_test_scaled_selected.values)\n",
    "mlaram_prob_preds = pd.DataFrame(mlaram_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "####################### Ensemble #########################\n",
    "ecc_xgb_preds = brca_ml_model_ecc_xgb.predict(X_test_scaled_selected)\n",
    "ecc_xgb_preds = pd.DataFrame(ecc_xgb_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "ecc_xgb_prob_preds = brca_ml_model_ecc_xgb.predict_proba(X_test_scaled_selected)\n",
    "ecc_xgb_prob_preds = normalize(np.array([ecc_xgb_prob_preds[i][:, 1] for i in range(5)]).transpose(), axis=1, norm='l1')\n",
    "ecc_xgb_prob_preds = pd.DataFrame(ecc_xgb_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "er_xgb_preds = brca_ml_model_er_xgb.predict(X_test_scaled_selected).todense()\n",
    "er_xgb_preds = pd.DataFrame(er_xgb_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "er_xgb_prob_preds = brca_ml_model_er_xgb.predict_proba(X_test_scaled_selected).todense()\n",
    "er_xgb_prob_preds = pd.DataFrame(er_xgb_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "ecc_rf_preds = brca_ml_model_ecc_rf.predict(X_test_scaled_selected)\n",
    "ecc_rf_preds = pd.DataFrame(ecc_rf_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "ecc_rf_prob_preds = brca_ml_model_ecc_rf.predict_proba(X_test_scaled_selected)\n",
    "ecc_rf_prob_preds = normalize(np.array([ecc_rf_prob_preds[i][:, 1] for i in range(5)]).transpose(), axis=1, norm='l1')\n",
    "ecc_rf_prob_preds = pd.DataFrame(ecc_rf_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "er_rf_preds = brca_ml_model_er_rf.predict(X_test_scaled_selected).todense()\n",
    "er_rf_preds = pd.DataFrame(er_rf_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "er_rf_prob_preds = brca_ml_model_er_rf.predict_proba(X_test_scaled_selected).todense()\n",
    "er_rf_prob_preds = pd.DataFrame(er_rf_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "ecc_lr_preds = brca_ml_model_ecc_lr.predict(X_test_scaled_selected)\n",
    "ecc_lr_preds = pd.DataFrame(ecc_lr_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "ecc_lr_prob_preds = brca_ml_model_ecc_lr.predict_proba(X_test_scaled_selected)\n",
    "ecc_lr_prob_preds = normalize(np.array([ecc_lr_prob_preds[i][:, 1] for i in range(5)]).transpose(), axis=1, norm='l1')\n",
    "ecc_lr_prob_preds = pd.DataFrame(ecc_lr_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "er_lr_preds = brca_ml_model_er_lr.predict(X_test_scaled_selected).todense()\n",
    "er_lr_preds = pd.DataFrame(er_lr_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "er_lr_prob_preds = brca_ml_model_er_lr.predict_proba(X_test_scaled_selected).todense()\n",
    "er_lr_prob_preds = pd.DataFrame(er_lr_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "ecc_svm_preds = brca_ml_model_ecc_svm.predict(X_test_scaled_selected)\n",
    "ecc_svm_preds = pd.DataFrame(ecc_svm_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "ecc_svm_prob_preds = brca_ml_model_ecc_svm.predict_proba(X_test_scaled_selected)\n",
    "ecc_svm_prob_preds = normalize(np.array([ecc_svm_prob_preds[i][:, 1] for i in range(5)]).transpose(), axis=1, norm='l1')\n",
    "ecc_svm_prob_preds = pd.DataFrame(ecc_svm_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "er_svm_preds = brca_ml_model_er_svm.predict(X_test_scaled_selected).todense()\n",
    "er_svm_preds = pd.DataFrame(er_svm_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "er_svm_prob_preds = brca_ml_model_er_svm.predict_proba(X_test_scaled_selected).todense()\n",
    "er_svm_prob_preds = pd.DataFrame(er_svm_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 0.7943037974683544\n",
      "Test relaxed accuracy (PAM50): 0.9715189873417721\n",
      "Test relaxed accuracy (original): 0.939873417721519\n",
      "Partial accuracy: 0.8924050632911392\n",
      "Test Hamming loss: 0.043670886075949364\n",
      "\n",
      "Ranking average precision:  0.9898206751054851\n",
      "Average precision:  0.9694695433285533\n",
      "Test precision (weighted): 0.9393440179395858\n",
      "Test recall (weighted): 0.9136842105263158\n",
      "Test f1 score (weighted): 0.9242453864492874\n",
      "\n",
      "Test precision (macro): 0.9445071010860484\n",
      "Test recall (macro): 0.8670346151482053\n",
      "Test f1 score (macro): 0.8991986318204764\n",
      "\n",
      "Test precision (micro): 0.9393939393939394\n",
      "Test recall (micro): 0.9136842105263158\n",
      "Test f1 score (micro): 0.9263607257203841\n",
      "\n",
      "Ordered subset acc: 0.7246835443037974\n",
      "Order 1 accuracy: 0.8829113924050633\n",
      "Order 2 accuracy: 0.7278481012658228\n",
      "Order 3 accuracy: 0.7246835443037974\n",
      "\n",
      "Secondary accuracy:  0.740506329113924\n"
     ]
    }
   ],
   "source": [
    "print_all_scores(y_test_5perc, er_xgb_preds, er_xgb_prob_preds, y_test_orig, y_test_pam50, y_test_corr, txt_file_name=None, k=[1, 2, 3])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_values = ['CRIS.A', 'CRIS.B', 'CRIS.C', 'CRIS.D', 'CRIS.E']\n",
    "with open('../data/tcga_cris_raw_24356_620samples.pkl', 'rb') as file:\n",
    "    data = pickle.load(file) \n",
    "X = data.drop(columns=['Patient ID', 'Subtype-from Parker centroids'] + label_values, inplace=False)\n",
    "y_pam50 = data['Subtype-from Parker centroids']\n",
    "y_orig = data['Subtype-from Parker centroids'] # this is not important\n",
    "\n",
    "# Take labels on whole dataset for PAM50\n",
    "y_corr = data[label_values]\n",
    "y_corr_non_neg = discard_negative_correlations(y_corr)\n",
    "\n",
    "# M-cut strategy to assign labels on whole dataset\n",
    "y_mcut_labels, _ = m_cut_strategy_class_assignment(y_corr, non_neg_values=True)\n",
    "y_mcut_labels_neg, _ = m_cut_strategy_class_assignment(y_corr, non_neg_values=False)\n",
    "\n",
    "# Compute labels from two strategies (M-cut and 5th percentile)\n",
    "y_mcut_5perc_labels, _ = create_mcut_nth_percentile_labels(\n",
    "    m_cut_labels=y_mcut_labels,\n",
    "    correlations=y_corr_non_neg,\n",
    "    y=y_pam50,\n",
    "    keep_primary=False,\n",
    "    N=5\n",
    ")\n",
    "\n",
    "X_train, X_test, \\\n",
    "y_train_pam50, y_test_pam50, \\\n",
    "y_train_mcut, y_test_mcut, \\\n",
    "y_train_orig, y_test_orig, \\\n",
    "y_train_5perc, y_test_5perc, \\\n",
    "y_train_corr, y_test_corr = \\\n",
    "    train_test_split(X, y_pam50, y_mcut_labels, y_orig, \n",
    "                    y_mcut_5perc_labels, y_corr_non_neg, test_size=0.3, random_state=1, stratify=y_pam50)\n",
    "\n",
    "# Data standardization | normalization\n",
    "X_train = X_train.divide(X_train.sum(axis=1), axis=0) * 1e6\n",
    "X_test = X_test.divide(X_test.sum(axis=1), axis=0) * 1e6\n",
    "scaler = FunctionTransformer(log_transform)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "\n",
    "# Load selected features\n",
    "with open('../data/cris/new2_without_corr_removed_feat_select_gt_40_perc_occur.pkl', 'rb') as file:\n",
    "    selected_feat = pickle.load(file)\n",
    "\n",
    "X_train_scaled_selected = X_train_scaled[list(selected_feat)]\n",
    "X_test_scaled_selected = X_test_scaled[list(selected_feat)]\n",
    "\n",
    "# One-hot encoding of original and PAM50 labels\n",
    "y_train_orig = pd.get_dummies(y_train_orig)\n",
    "y_test_orig = pd.get_dummies(y_test_orig)\n",
    "y_train_pam50 = pd.get_dummies(y_train_pam50)\n",
    "y_test_pam50 = pd.get_dummies(y_test_pam50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_brca_sl = '../final_results/CRIS/single-label/01-14-52/'\n",
    "\n",
    "# Loading the best models for each approach in single-label\n",
    "with open(os.path.join(path_brca_sl, 'bestmodel_XGBoost_run_01-09-2023_03:49:46.pkl'), 'rb') as f:\n",
    "    cris_model_xgb = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(path_brca_sl, 'bestmodel_LogisticRegression_run_01-09-2023_01:15:05.pkl'), 'rb') as f:\n",
    "    cris_model_lr = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(path_brca_sl, 'bestmodel_RandomForest_run_01-09-2023_01:42:48.pkl'), 'rb') as f:\n",
    "    cris_model_rf = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(path_brca_sl, 'bestmodel_SVC_run_01-09-2023_01:59:53.pkl'), 'rb') as f:\n",
    "    cris_model_svm = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(path_brca_sl, 'bestmodel_AdaBoost_run_01-09-2023_03:41:42.pkl'), 'rb') as f:\n",
    "    cris_model_adaboost = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(path_brca_sl, 'bestmodel_DecisionTree_run_01-09-2023_01:37:16.pkl'), 'rb') as f:\n",
    "    cris_model_dectree = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(path_brca_sl, 'bestmodel_KNN_run_01-09-2023_01:36:57.pkl'), 'rb') as f:\n",
    "    cris_model_knn = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(path_brca_sl, 'bestmodel_LightGBM_run_01-09-2023_02:21:39.pkl'), 'rb') as f:\n",
    "    cris_model_lgbm = pickle.load(f)\n",
    "\n",
    "# Compute predictions\n",
    "xgb_preds = cris_model_xgb.predict(X_test_scaled_selected)\n",
    "xgb_preds = pd.Series(xgb_preds, index=y_test_5perc.index).map(mapping)\n",
    "\n",
    "lr_preds = cris_model_lr.predict(X_test_scaled_selected)\n",
    "lr_preds = pd.Series(lr_preds, index=y_test_5perc.index).map(mapping)\n",
    "\n",
    "svm_preds = cris_model_svm.predict(X_test_scaled_selected)\n",
    "svm_preds = pd.Series(svm_preds, index=y_test_5perc.index).map(mapping)\n",
    "\n",
    "rf_preds = cris_model_rf.predict(X_test_scaled_selected)\n",
    "rf_preds = pd.Series(rf_preds, index=y_test_5perc.index).map(mapping)\n",
    "# ----------\n",
    "ada_preds = cris_model_adaboost.predict(X_test_scaled_selected)\n",
    "ada_preds = pd.Series(ada_preds, index=y_test_5perc.index).map(mapping)\n",
    "\n",
    "knn_preds = cris_model_knn.predict(X_test_scaled_selected)\n",
    "knn_preds = pd.Series(knn_preds, index=y_test_5perc.index).map(mapping)\n",
    "\n",
    "dectree_preds = cris_model_dectree.predict(X_test_scaled_selected)\n",
    "dectree_preds = pd.Series(dectree_preds, index=y_test_5perc.index).map(mapping)\n",
    "\n",
    "lgbm_preds = cris_model_lgbm.predict(X_test_scaled_selected)\n",
    "lgbm_preds = pd.Series(lgbm_preds, index=y_test_5perc.index).map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_brca_ml = '../final_results/CRIS/multi-label'\n",
    "path_brca_ml_pt = os.path.join(path_brca_ml, '01-09-2023_05:58:37')\n",
    "\n",
    "# Logistic Regression - Binary Relevance\n",
    "with open(os.path.join(path_brca_ml_pt, 'BR_LRegression_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_lr_br = pickle.load(file)\n",
    "# Logistic Regression - Classifier Chain \n",
    "with open(os.path.join(path_brca_ml_pt, 'CC_LRegression_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_lr_cc = pickle.load(file)\n",
    "# Logistic Regression - Label Powerset\n",
    "with open(os.path.join(path_brca_ml_pt, 'LP_LRegression_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_lr_lp = pickle.load(file)\n",
    "\n",
    "# XGBoost - Binary Relevance\n",
    "with open(os.path.join(path_brca_ml_pt, 'BR_XGBoost_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_xgb_br = pickle.load(file)\n",
    "# XGBoost - Classifier Chain \n",
    "with open(os.path.join(path_brca_ml_pt, 'CC_XGBoost_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_xgb_cc = pickle.load(file)\n",
    "# XGBoost - Label Powerset\n",
    "with open(os.path.join(path_brca_ml_pt, 'LP_XGBoost_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_xgb_lp = pickle.load(file)\n",
    "\n",
    "# Random Forest - Binary Relevance\n",
    "with open(os.path.join(path_brca_ml_pt, 'BR_RForest_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_rf_br = pickle.load(file)\n",
    "# Random Forest - Classifier Chain\n",
    "with open(os.path.join(path_brca_ml_pt, 'CC_RForest_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_rf_cc = pickle.load(file)\n",
    "# Random Forest - Label Powesret\n",
    "with open(os.path.join(path_brca_ml_pt, 'LP_RForest_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_rf_lp = pickle.load(file)\n",
    "\n",
    "# SVC - Binary Relevance \n",
    "with open(os.path.join(path_brca_ml_pt, 'BR_SVC_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_svm_br = pickle.load(file)\n",
    "# SVC - Classifier Chain\n",
    "with open(os.path.join(path_brca_ml_pt, 'CC_SVC_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_svm_cc = pickle.load(file)\n",
    "# SVC - Label Powesret\n",
    "with open(os.path.join(path_brca_ml_pt, 'LP_SVC_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_svm_lp = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ Algorithm Adaptation and Ensemble #############################\n",
    "path_brca_ml_aa = os.path.join(path_brca_ml, '01-09-2023_12:14:22')\n",
    "\n",
    "with open(os.path.join(path_brca_ml_aa, 'MLkNN_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_mlknn = pickle.load(file)\n",
    "with open(os.path.join(path_brca_ml_aa, 'MLARAM_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_mlaram = pickle.load(file)\n",
    "\n",
    "with open(os.path.join(path_brca_ml_aa, 'EnsembleCC_XGBoost_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_ecc_xgb = pickle.load(file)\n",
    "with open(os.path.join(path_brca_ml_aa, 'EnsembleCC_RForest_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_ecc_rf = pickle.load(file)\n",
    "with open(os.path.join(path_brca_ml_aa, 'EnsembleCC_LRegression_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_ecc_lr = pickle.load(file)\n",
    "with open(os.path.join(path_brca_ml_aa, 'EnsembleCC_SVC_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_ecc_svm = pickle.load(file)\n",
    "\n",
    "with open(os.path.join(path_brca_ml_aa, 'EnsembleRakel_XGBoost_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_er_xgb = pickle.load(file)\n",
    "with open(os.path.join(path_brca_ml_aa, 'EnsembleRakel_RForest_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_er_rf = pickle.load(file)\n",
    "with open(os.path.join(path_brca_ml_aa, 'EnsembleRakel_LRegression_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_er_lr = pickle.load(file)\n",
    "with open(os.path.join(path_brca_ml_aa, 'EnsembleRakel_SVC_mcut_5perc_bestmodel.pkl'), 'rb') as file:\n",
    "    brca_ml_model_er_svm = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': LogisticRegression(C=5, random_state=4, solver='sag', tol=0.01), 'classifier__C': 5, 'classifier__class_weight': None, 'classifier__dual': False, 'classifier__fit_intercept': True, 'classifier__intercept_scaling': 1, 'classifier__l1_ratio': None, 'classifier__max_iter': 100, 'classifier__multi_class': 'auto', 'classifier__n_jobs': None, 'classifier__penalty': 'l2', 'classifier__random_state': 4, 'classifier__solver': 'sag', 'classifier__tol': 0.01, 'classifier__verbose': 0, 'classifier__warm_start': False, 'require_dense': [True, True]}\n"
     ]
    }
   ],
   "source": [
    "print(brca_ml_model_lr_br.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Define a mapping dictionary\n",
    "mapping = {0: 'Basal', 1: 'Her2', 2: 'LumA', 3: 'LumB', 4: 'Normal'}\n",
    "\n",
    "############################### XGBoost ###############################\n",
    "xgb_br_preds = brca_ml_model_xgb_br.predict(X_test_scaled_selected).toarray()\n",
    "xgb_br_preds = pd.DataFrame(xgb_br_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "xgb_br_prob_preds = brca_ml_model_xgb_br.predict_proba(X_test_scaled_selected).toarray()\n",
    "xgb_br_prob_preds = pd.DataFrame(xgb_br_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "xgb_cc_preds = brca_ml_model_xgb_cc.predict(X_test_scaled_selected).toarray()\n",
    "xgb_cc_preds = pd.DataFrame(xgb_cc_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "xgb_cc_prob_preds = brca_ml_model_xgb_cc.predict_proba(X_test_scaled_selected).toarray()\n",
    "xgb_cc_prob_preds = pd.DataFrame(xgb_cc_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "# ############################### Logistic Regression ###############################\n",
    "lr_br_preds = brca_ml_model_lr_br.predict(X_test_scaled_selected).toarray()\n",
    "lr_br_preds = pd.DataFrame(lr_br_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "lr_br_prob_preds = brca_ml_model_lr_br.predict_proba(X_test_scaled_selected).toarray()\n",
    "lr_br_prob_preds = pd.DataFrame(lr_br_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "lr_cc_preds = brca_ml_model_lr_cc.predict(X_test_scaled_selected).toarray()\n",
    "lr_cc_preds = pd.DataFrame(lr_cc_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "lr_cc_prob_preds = brca_ml_model_lr_cc.predict_proba(X_test_scaled_selected).toarray()\n",
    "lr_cc_prob_preds = pd.DataFrame(lr_cc_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "# ############################### SVM ###############################\n",
    "svm_lp_preds = brca_ml_model_svm_lp.predict(X_test_scaled_selected).toarray()\n",
    "svm_lp_preds = pd.DataFrame(svm_lp_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "svm_lp_prob_preds = brca_ml_model_svm_lp.predict_proba(X_test_scaled_selected).toarray()\n",
    "svm_lp_prob_preds = pd.DataFrame(svm_lp_prob_preds, index=y_test_5perc.index, columns=y_test_5perc.columns)\n",
    "\n",
    "# ############################### Random Forest ###############################\n",
    "rf_lp_preds = brca_ml_model_rf_lp.predict(X_test_scaled_selected).toarray()\n",
    "rf_lp_preds = pd.DataFrame(rf_lp_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "rf_lp_prob_preds = brca_ml_model_rf_lp.predict_proba(X_test_scaled_selected).toarray()\n",
    "rf_lp_prob_preds = pd.DataFrame(rf_lp_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "# NOT OPTIMAL\n",
    "xgb_lp_preds = brca_ml_model_xgb_lp.predict(X_test_scaled_selected).toarray()\n",
    "xgb_lp_preds = pd.DataFrame(xgb_lp_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "xgb_lp_prob_preds = brca_ml_model_xgb_lp.predict_proba(X_test_scaled_selected).toarray()\n",
    "xgb_lp_prob_preds = pd.DataFrame(xgb_lp_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "lr_lp_preds = brca_ml_model_lr_lp.predict(X_test_scaled_selected).toarray()\n",
    "lr_lp_preds = pd.DataFrame(lr_lp_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "lr_lp_prob_preds = brca_ml_model_lr_lp.predict_proba(X_test_scaled_selected).toarray()\n",
    "lr_lp_prob_preds = pd.DataFrame(lr_lp_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "svm_br_preds = brca_ml_model_svm_br.predict(X_test_scaled_selected).toarray()\n",
    "svm_br_preds = pd.DataFrame(svm_br_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "svm_br_prob_preds = brca_ml_model_svm_br.predict_proba(X_test_scaled_selected).toarray()\n",
    "svm_br_prob_preds = pd.DataFrame(svm_br_prob_preds, index=y_test_5perc.index, columns=y_test_5perc.columns)\n",
    "\n",
    "svm_cc_preds = brca_ml_model_svm_cc.predict(X_test_scaled_selected).toarray()\n",
    "svm_cc_preds = pd.DataFrame(svm_cc_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "svm_cc_prob_preds = brca_ml_model_svm_cc.predict_proba(X_test_scaled_selected).toarray()\n",
    "svm_cc_prob_preds = pd.DataFrame(svm_cc_prob_preds, index=y_test_5perc.index, columns=y_test_5perc.columns)\n",
    "\n",
    "rf_br_preds = brca_ml_model_rf_br.predict(X_test_scaled_selected).toarray()\n",
    "rf_br_preds = pd.DataFrame(rf_br_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "rf_br_prob_preds = brca_ml_model_rf_br.predict_proba(X_test_scaled_selected).toarray()\n",
    "rf_br_prob_preds = pd.DataFrame(rf_br_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "rf_cc_preds = brca_ml_model_rf_cc.predict(X_test_scaled_selected).toarray()\n",
    "rf_cc_preds = pd.DataFrame(rf_cc_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "rf_cc_prob_preds = brca_ml_model_rf_cc.predict_proba(X_test_scaled_selected).toarray()\n",
    "rf_cc_prob_preds = pd.DataFrame(rf_cc_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "############################ Algorithm Adaptation #############################\n",
    "mlknn_preds = brca_ml_model_mlknn.predict(X_test_scaled_selected).toarray()\n",
    "mlknn_preds = pd.DataFrame(mlknn_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "mlknn_prob_preds = brca_ml_model_mlknn.predict_proba(X_test_scaled_selected).toarray()\n",
    "mlknn_prob_preds = pd.DataFrame(mlknn_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "mlaram_preds = brca_ml_model_mlaram.predict(X_test_scaled_selected.values)\n",
    "mlaram_preds = pd.DataFrame(mlaram_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "mlaram_prob_preds = brca_ml_model_mlaram.predict_proba(X_test_scaled_selected.values)\n",
    "mlaram_prob_preds = pd.DataFrame(mlaram_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "####################### Ensemble #########################\n",
    "ecc_xgb_preds = brca_ml_model_ecc_xgb.predict(X_test_scaled_selected)\n",
    "ecc_xgb_preds = pd.DataFrame(ecc_xgb_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "ecc_xgb_prob_preds = brca_ml_model_ecc_xgb.predict_proba(X_test_scaled_selected)\n",
    "ecc_xgb_prob_preds = normalize(np.array([ecc_xgb_prob_preds[i][:, 1] for i in range(5)]).transpose(), axis=1, norm='l1')\n",
    "ecc_xgb_prob_preds = pd.DataFrame(ecc_xgb_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "er_xgb_preds = brca_ml_model_er_xgb.predict(X_test_scaled_selected).todense()\n",
    "er_xgb_preds = pd.DataFrame(er_xgb_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "er_xgb_prob_preds = brca_ml_model_er_xgb.predict_proba(X_test_scaled_selected).todense()\n",
    "er_xgb_prob_preds = pd.DataFrame(er_xgb_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "ecc_rf_preds = brca_ml_model_ecc_rf.predict(X_test_scaled_selected)\n",
    "ecc_rf_preds = pd.DataFrame(ecc_rf_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "ecc_rf_prob_preds = brca_ml_model_ecc_rf.predict_proba(X_test_scaled_selected)\n",
    "ecc_rf_prob_preds = normalize(np.array([ecc_rf_prob_preds[i][:, 1] for i in range(5)]).transpose(), axis=1, norm='l1')\n",
    "ecc_rf_prob_preds = pd.DataFrame(ecc_rf_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "er_rf_preds = brca_ml_model_er_rf.predict(X_test_scaled_selected).todense()\n",
    "er_rf_preds = pd.DataFrame(er_rf_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "er_rf_prob_preds = brca_ml_model_er_rf.predict_proba(X_test_scaled_selected).todense()\n",
    "er_rf_prob_preds = pd.DataFrame(er_rf_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "ecc_lr_preds = brca_ml_model_ecc_lr.predict(X_test_scaled_selected)\n",
    "ecc_lr_preds = pd.DataFrame(ecc_lr_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "ecc_lr_prob_preds = brca_ml_model_ecc_lr.predict_proba(X_test_scaled_selected)\n",
    "ecc_lr_prob_preds = normalize(np.array([ecc_lr_prob_preds[i][:, 1] for i in range(5)]).transpose(), axis=1, norm='l1')\n",
    "ecc_lr_prob_preds = pd.DataFrame(ecc_lr_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "er_lr_preds = brca_ml_model_er_lr.predict(X_test_scaled_selected).todense()\n",
    "er_lr_preds = pd.DataFrame(er_lr_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "er_lr_prob_preds = brca_ml_model_er_lr.predict_proba(X_test_scaled_selected).todense()\n",
    "er_lr_prob_preds = pd.DataFrame(er_lr_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "ecc_svm_preds = brca_ml_model_ecc_svm.predict(X_test_scaled_selected)\n",
    "ecc_svm_preds = pd.DataFrame(ecc_svm_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "ecc_svm_prob_preds = brca_ml_model_ecc_svm.predict_proba(X_test_scaled_selected)\n",
    "ecc_svm_prob_preds = normalize(np.array([ecc_svm_prob_preds[i][:, 1] for i in range(5)]).transpose(), axis=1, norm='l1')\n",
    "ecc_svm_prob_preds = pd.DataFrame(ecc_svm_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)\n",
    "\n",
    "er_svm_preds = brca_ml_model_er_svm.predict(X_test_scaled_selected).todense()\n",
    "er_svm_preds = pd.DataFrame(er_svm_preds, columns=y_test_5perc.columns, index=y_test_5perc.index, dtype='int')\n",
    "er_svm_prob_preds = brca_ml_model_er_svm.predict_proba(X_test_scaled_selected).todense()\n",
    "er_svm_prob_preds = pd.DataFrame(er_svm_prob_preds, columns=y_test_5perc.columns, index=y_test_5perc.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 0.6397849462365591\n",
      "Test relaxed accuracy (PAM50): 0.7849462365591398\n",
      "Test relaxed accuracy (original): 0.7849462365591398\n",
      "Partial accuracy: 0.7123655913978495\n",
      "Test Hamming loss: 0.08924731182795699\n",
      "\n",
      "Ranking average precision:  0.9310035842293908\n",
      "Average precision:  0.8891493651745336\n",
      "Test precision (weighted): 0.8712156003828593\n",
      "Test recall (weighted): 0.7400881057268722\n",
      "Test f1 score (weighted): 0.7981709343616163\n",
      "\n",
      "Test precision (macro): 0.8628247141150368\n",
      "Test recall (macro): 0.7171137886655129\n",
      "Test f1 score (macro): 0.7811833324089993\n",
      "\n",
      "Test precision (micro): 0.875\n",
      "Test recall (micro): 0.7400881057268722\n",
      "Test f1 score (micro): 0.8019093078758949\n",
      "\n",
      "Ordered subset acc: 0.6129032258064516\n",
      "Order 1 accuracy: 0.7634408602150538\n",
      "Order 2 accuracy: 0.6129032258064516\n",
      "Order 3 accuracy: 0.6129032258064516\n",
      "\n",
      "Secondary accuracy:  0.7634408602150538\n"
     ]
    }
   ],
   "source": [
    "print_all_scores(y_test_5perc, xgb_br_preds, xgb_br_prob_preds, y_test_orig, y_test_pam50, y_test_corr, txt_file_name=None, k=[1, 2, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bca_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
